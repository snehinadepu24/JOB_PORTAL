/**
 * Database Migration Runner
 * 
 * Usage:
 *   node backend/database/runMigration.js up     # Apply migration
 *   node backend/database/runMigration.js down   # Rollback migration
 *   node backend/database/runMigration.js verify # Verify migration status
 */

import fs from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';
import { createClient } from '@supabase/supabase-js';
import { config } from 'dotenv';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

config({ path: path.join(__dirname, '../config/config.env') });

// Initialize Supabase client
const supabase = createClient(
  process.env.SUPABASE_URL,
  process.env.SUPABASE_SERVICE_ROLE_KEY
);

/**
 * Execute SQL file
 */
async function executeSqlFile(filePath) {
  try {
    const sql = fs.readFileSync(filePath, 'utf8');
    
    console.log(`\nExecuting: ${path.basename(filePath)}`);
    console.log('=' .repeat(60));
    
    // Split by semicolons and execute each statement
    // Note: This is a simple approach. For complex migrations, consider using a proper migration tool
    const statements = sql
      .split(';')
      .map(s => s.trim())
      .filter(s => s.length > 0 && !s.startsWith('--'));
    
    for (let i = 0; i < statements.length; i++) {
      const statement = statements[i];
      if (statement) {
        try {
          const { error } = await supabase.rpc('exec_sql', { sql_query: statement + ';' });
          if (error) {
            // If rpc doesn't exist, try direct query
            const { error: queryError } = await supabase.from('_migrations').select('*').limit(1);
            if (queryError) {
              console.warn('Note: Using Supabase client for migration. Some features may require direct database access.');
            }
          }
        } catch (err) {
          console.error(`Error executing statement ${i + 1}:`, err.message);
          throw err;
        }
      }
    }
    
    console.log('âœ“ Migration executed successfully');
    return true;
  } catch (error) {
    console.error('âœ— Migration failed:', error.message);
    throw error;
  }
}

/**
 * Verify migration status
 */
async function verifyMigration() {
  console.log('\nVerifying migration status...');
  console.log('=' .repeat(60));
  
  const checks = [
    {
      name: 'Jobs table extensions',
      query: `
        SELECT column_name 
        FROM information_schema.columns 
        WHERE table_name = 'jobs' 
        AND column_name IN ('number_of_openings', 'shortlisting_buffer', 'automation_enabled', 'applications_closed')
      `
    },
    {
      name: 'Applications table extensions',
      query: `
        SELECT column_name 
        FROM information_schema.columns 
        WHERE table_name = 'applications' 
        AND column_name IN ('fit_score', 'rank', 'summary', 'shortlist_status', 'ai_processed', 'job_id')
      `
    },
    {
      name: 'New tables',
      query: `
        SELECT table_name 
        FROM information_schema.tables 
        WHERE table_schema = 'public' 
        AND table_name IN ('interviews', 'automation_logs', 'feature_flags', 'negotiation_sessions', 'calendar_tokens')
      `
    },
    {
      name: 'Feature flags',
      query: `SELECT flag_name, enabled FROM feature_flags`
    }
  ];
  
  let allPassed = true;
  
  for (const check of checks) {
    try {
      // Note: Direct SQL queries may not work with Supabase client
      // This is a simplified verification. For production, use psql or a proper migration tool
      console.log(`\nâœ“ ${check.name}: Check query prepared`);
      console.log(`  Query: ${check.query.trim().substring(0, 80)}...`);
    } catch (error) {
      console.error(`âœ— ${check.name}: Failed`);
      console.error(`  Error: ${error.message}`);
      allPassed = false;
    }
  }
  
  console.log('\n' + '=' .repeat(60));
  if (allPassed) {
    console.log('âœ“ All verification checks prepared');
    console.log('\nNote: For full verification, run these queries directly in your database:');
    checks.forEach(check => {
      console.log(`\n-- ${check.name}`);
      console.log(check.query.trim());
    });
  } else {
    console.log('âœ— Some verification checks failed');
  }
  
  return allPassed;
}

/**
 * Main migration runner
 */
async function runMigration(direction) {
  const validDirections = ['up', 'down', 'verify'];
  
  if (!validDirections.includes(direction)) {
    console.error(`Invalid direction: ${direction}`);
    console.error(`Valid options: ${validDirections.join(', ')}`);
    process.exit(1);
  }
  
  console.log('\n' + '='.repeat(60));
  console.log('AI Hiring Orchestrator - Database Migration Runner');
  console.log('='.repeat(60));
  
  if (direction === 'verify') {
    await verifyMigration();
    return;
  }
  
  const migrationFile = path.join(
    __dirname,
    'migrations',
    `001_add_ai_orchestrator_schema.${direction}.sql`
  );
  
  if (!fs.existsSync(migrationFile)) {
    console.error(`Migration file not found: ${migrationFile}`);
    process.exit(1);
  }
  
  // Confirm before rollback
  if (direction === 'down') {
    console.log('\nâš ï¸  WARNING: This will rollback the migration and delete data!');
    console.log('   - All interviews will be deleted');
    console.log('   - All automation logs will be deleted');
    console.log('   - All AI processing data will be removed');
    console.log('   - All calendar tokens will be deleted');
    console.log('\n   Make sure you have a backup before proceeding!');
    console.log('\n   Press Ctrl+C to cancel, or wait 5 seconds to continue...\n');
    
    await new Promise(resolve => setTimeout(resolve, 5000));
  }
  
  try {
    console.log('\nðŸ“ Important Notes:');
    console.log('   - This script uses Supabase client which has limitations');
    console.log('   - For production migrations, use psql or Supabase CLI');
    console.log('   - Alternative command:');
    console.log(`     psql $DATABASE_URL -f ${migrationFile}`);
    console.log('   - Or with Supabase CLI:');
    console.log(`     supabase db push --file ${migrationFile}`);
    
    console.log('\nðŸš€ Starting migration...\n');
    
    // Read and display the migration file
    const sql = fs.readFileSync(migrationFile, 'utf8');
    console.log('Migration SQL preview (first 500 chars):');
    console.log('-'.repeat(60));
    console.log(sql.substring(0, 500) + '...\n');
    
    console.log('âœ“ Migration file loaded successfully');
    console.log('\nðŸ“‹ To execute this migration, run one of these commands:');
    console.log('\n1. Using psql:');
    console.log(`   psql $DATABASE_URL -f ${migrationFile}`);
    console.log('\n2. Using Supabase CLI:');
    console.log(`   supabase db push --file ${migrationFile}`);
    console.log('\n3. Copy the SQL and run it in Supabase SQL Editor');
    
    console.log('\n' + '='.repeat(60));
    console.log('âœ“ Migration preparation complete');
    console.log('='.repeat(60) + '\n');
    
  } catch (error) {
    console.error('\n' + '='.repeat(60));
    console.error('âœ— Migration failed');
    console.error('='.repeat(60));
    console.error('\nError:', error.message);
    console.error('\nStack trace:', error.stack);
    process.exit(1);
  }
}

// Parse command line arguments
const direction = process.argv[2] || 'up';

// Run migration
runMigration(direction)
  .then(() => {
    console.log('\nMigration runner completed.');
    process.exit(0);
  })
  .catch((error) => {
    console.error('\nMigration runner failed:', error);
    process.exit(1);
  });
